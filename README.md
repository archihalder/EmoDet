<h1 align='center'>EmoDet</h1>

### Description

A project which detects a person's face and predicts his/her emotions using OpenCV and Deep Learning.

---

### Dataset

The dataset used in making this project is FER-2013 dataset. The data consists of 48x48 pixel grayscale images of faces. The faces have been automatically registered so that the face is more or less centred and occupies about the same amount of space in each image.

The dataset is categorized into seven categories based on the facial expressions (Angry, Disgust, Fear, Happy, Sad, Surprise, Neutral). The training set consists of 28,709 examples and the public test set consists of 3,589 examples.

The dataset can be accessed by clicking <a href='https://www.kaggle.com/msambare/fer2013'>here</a>.

---

### Model Architecture

---

### User Guide

1. Clone the project to you local machine

```bash
git clone git@github.com:archihalder/EmoDet.git
```

2. Enter the directory

```bash
cd EmoDet
```

3. Get the required modules to run

```bash
pip install -r requirements.txt
```

4. Enter src directory

```bash
cd src
```

5. Run the file

```bash
python3 video.py
```

---

### Demonstration

---

### Contributors

1. <a href = "https://github.com/archihalder">Archi Halder</a>
2. <a href = "https://github.com/mishra1683">Aditya Mishra</a>
